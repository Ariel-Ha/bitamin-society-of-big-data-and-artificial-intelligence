{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pandas_missing_value_sampling_scaling_exercises_판다스_결측치_샘플링_스케일링_연습문제.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeonJin55/bitamin-society-of-big-data-and-artificial-intelligence/blob/main/pandas_missing_value_sampling_scaling_exercises_%ED%8C%90%EB%8B%A4%EC%8A%A4_%EA%B2%B0%EC%B8%A1%EC%B9%98_%EC%83%98%ED%94%8C%EB%A7%81_%EC%8A%A4%EC%BC%80%EC%9D%BC%EB%A7%81_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtbBK1fjJTAJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns # 시각화를 위한 라이브러리\n",
        "import matplotlib.pyplot as plt\n",
        "import calendar\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 데이터 전처리"
      ],
      "metadata": {
        "id": "afXz5pyuJu2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "한국환경공단에서 발표한 미세먼지 관련 자료를 분석하려고 데이터를 사용하려고 합니다. <p>\n",
        "'SeoulHourlyAvgAirPollution.csv' 을 불러와 pollution 으로 저장해주세요."
      ],
      "metadata": {
        "id": "Slq3kEuePV6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#colab에 SeoulHourlyAvgAirPollution.csv 파일 업로드\n",
        "from google.colab import files\n",
        "import io\n",
        "SeoulHourlyAvgAirPollution_data=files.upload()\n",
        "pollution =pd.read_csv(io.BytesIO(SeoulHourlyAvgAirPollution_data[\"SeoulHourlyAvgAirPollution.csv\"]))"
      ],
      "metadata": {
        "id": "bPZGr2PXJVUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [2-1] Label Encoding\n",
        "'측정소명' 변수를 레이블 인코딩하고, 레이블 인코딩한 값을 기존 데이터 프레임에 '측정소명_인코딩'라는 열로 추가해보세요."
      ],
      "metadata": {
        "id": "xj6TXw2BKpDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "qs_ZNaUnUHlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [2-2] 결측치, 중복값 처리\n",
        "한국환경공단에서 발표한 미세먼지 관련 자료를 분석하려고 데이터를 사용하려고 합니다.우선, 칼럼별 결측치의 개수를 구해주세요."
      ],
      "metadata": {
        "id": "lZQjY5HQKspe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 칼럼별 결측치 개수 확인"
      ],
      "metadata": {
        "id": "ClcesVrwKwRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a. 결측치 처리하기\n",
        "결측치를 대체하거나, 제외하려고 합니다. 아래의 조건에 맞게 데이터를 수정해주세요. (inplace=True)\n",
        "\n",
        "1) '이산화질소농도'는 결측치를 제거 <p>\n",
        "2) '이산화질소농도'는 데이터에서 제외 <p>\n",
        "3) '일산화탄소농도'는 바로 위 행의 데이터로 대체 <p>\n",
        "4) '아황산가스' 는 결측치 값을 0으로 대체 (조건: replace() 메소드 사용) <p>\n",
        "5) '미세먼지'의 결측치는 열의 평균값으로 대체 <p>\n",
        "6) '초미세먼지'의 결측치는 최빈값으로 대체"
      ],
      "metadata": {
        "id": "navovKUJK_Rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U2JfSeJZLAp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b. 중복값 처리하기\n",
        "DUPLICATED.csv 를 불러와, duplicates 에 저장해주세요.\n",
        "\n",
        "duplicates를 분석해보니, 같은 사람에 대해서 중복된 데이터가 존재합니다. <p>\n",
        "'NAME' 과 'ID' 가 모두 중복이면, 처음 나온 데이터가 올바른 값입니다. <p>\n",
        "'NAME' 은 중복이지만, 'ID'가 중복이지 않으면, 잘못된 데이터입니다. <p>\n",
        "잘못된 데이터는 삭제해주시고, 중복값을 적절하게 처리하여 데이터를 수정해주세요."
      ],
      "metadata": {
        "id": "S_-RFLgILCPP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[2-3] 불균형 데이터 처리\n",
        "## <서술형 문항>\n",
        "Pollution 데이터을 분류 하려고 하는데, 불균형 데이터 처리 단계를 거쳐야 합니다.\n",
        "불균형 데이터가 무엇인지 설명하고, Undersampling 과 Oversampling 이 무엇인지 간단하게 설명해주세요. (간단히만 적어주시면 됩니다!)"
      ],
      "metadata": {
        "id": "nFvYci6PLQYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g1WK02beLDfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### under sampling\n",
        "'train' 데이터프레임을 사용하여, x는 'count', 'registered', y는 'workingday'로 x 와 y 값을 설정하세요. 위 x,y 에 대하여 under sampliing 기법 중 하나를 선택하여 불균형 데이터 처리를 진행하고 어떻게 데이터가 변화하였는데 살펴보세요. \n",
        "(hint: shape, value_counts 등을 통해 샘플링 전후 데이터 개수의 변화를 알 수 있습니다.)<p>"
      ],
      "metadata": {
        "id": "ovtsSBSQZmB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import *"
      ],
      "metadata": {
        "id": "HURemEI_adPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = train[['count', 'registered']]\n",
        "y = train[['workingday']]\n",
        "print((y==1).sum())\n",
        "print((y==0).sum())\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "9A3wWipZat6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_resampled, y_resampled = RandomUnderSampler(random_state =0).fit_resample(x,y)\n",
        "x_resampled.shape\n",
        "y_resampled.shape\n",
        "print((y_resampled==1).sum())\n",
        "print((y_resampled==0).sum())"
      ],
      "metadata": {
        "id": "-3DtHr1JdidK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[2-4] Feature Scaling\n",
        "날씨와 ('weather' 칼럼) 과 전체 대여된 자전거 수 ('count' 칼럼) 을 비교하기 위하여 Feature Scaling 하고자 합니다. <p>\n",
        "두 변수 모두 정규화를 적용한 후, 'weather scaled' 및 'count scaled' 으로 저장하여, 각 변수 정규화 저용 전 후 평균과 분산을 비교해주세요."
      ],
      "metadata": {
        "id": "AKb44oRveEx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler2 = StandardScaler()"
      ],
      "metadata": {
        "id": "oqPx8rMEhCrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler1 = MinMaxScaler()"
      ],
      "metadata": {
        "id": "h_y5Hlf7hZIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Weather 의 정규화 적용 전 평균과 분산 비교')\n",
        "print(train[['weather', 'weather scaled']].mean())\n",
        "print(train[['weather', 'weather scaled']].var())\n",
        "\n",
        "print('Count 의 정규화 적용 전 평균과 분산 비교')\n",
        "print(train[['count', 'count scaled']].mean())\n",
        "print(train[['count', 'count scaled']].var())"
      ],
      "metadata": {
        "id": "9yD2vYhcgmmU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}